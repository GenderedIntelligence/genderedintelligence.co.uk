#!/usr/bin/perl -w
#
# reduce-repeated-logs:
# Finds messages with lots of duplicated log lines. Merges the adjacent
# duplicates into one log line, with number of repetitions after it.
#
# e.g.
# unexpected error (type RABX::Error::User) while processing message: Representative ID '13531' not found (repeated 16138 times)
#
# By default, scans all messages with more log file entries than $low below.
# Specify a message id to do just that message.
#
# Copyright (c) 2013 UK Citizens Online Democracy. All rights reserved.
# Email: matthew@mysociety.org; WWW: http://www.mysociety.org/

use strict;
require 5.8.0;

# Number of lines which must exactly repeat within a message for this script to
# look for adjacent duplicates within that message.
my $low = 1000;

# Horrible boilerplate to set up appropriate library paths.
use FindBin;
use lib "$FindBin::Bin/../perllib";
use lib "$FindBin::Bin/../commonlib/perllib";

use Data::Dumper;

use mySociety::Config;
BEGIN {
    mySociety::Config::set_file("$FindBin::Bin/../conf/general");
}
use mySociety::DBHandle qw(dbh);
#DBI->trace(1);
use FYR;

# Takes an array of ids of duplicate message_log items (perhaps duplicating
# every two or three rows), and an extra count to add to this. Deletes all of
# the message except the last one, and appends total count to that.
sub merge_messages {
    my ($dups, $c_extra, $num) = @_;
    my @dups = @$dups;
    my $c = int( (scalar(@dups) + $c_extra) / $num );
    my @last = splice(@dups, -$num);
    #print Dumper(\@dups);
    #print "count: " . $c . "\n";
    #print "last: " . join(" ", @last) . "\n";
    while (scalar(@dups) > 5000) {
        my @start = @dups[0..5000];
        @dups = @dups[5001..$#dups];
        dbh()->do("delete from message_log where order_id in (". join(",", @start) . ")");
    }
    dbh()->do("delete from message_log where order_id in (". join(",", @dups) . ")");
    foreach my $last (@last) {
        dbh()->do("update message_log set message =
            (replace(message, coalesce(substring(message from ' \\\\(repeated .+ times\\\\)\$'), ''),'')
            || ' (repeated $c times)') where order_id = ?", {}, $last);
    }
    dbh()->commit();
}

# Takes a message id, and merges adjacent duplicate message_log items for that message.
sub reduce_log($) {
    my ($message_id) = @_;
    my $stm = dbh()->prepare("
        select order_id, exceptional, whenlogged, state, message, editor
        from message_log where message_id = ? order by order_id");
    $stm->execute($message_id);
    my ($p_exceptional, $p_whenlogged, $p_state, $p_message, $p_editor);
    my ($p_p_message, $p_p_p_message);
    my @dups;
    my $c_extra = 0;
    my $matching_pairs = 0;
    my $matching_threes = 0;
    while (my ($order_id, $exceptional, $whenlogged, $state, $message, $editor) = $stm->fetchrow_array()) {
        $editor = '' if (!$editor);
        if ($message =~ m/^(.+) \(repeated (?:in pair about )?(\d+) times\)$/) {
            $message = $1;
            my $c_message = $2 - 1;
            $c_extra += ($c_message - 1);
        }
        #print scalar(@dups) . " $order_id $exceptional $whenlogged $state $message $editor\n";

        # See if meta data same as last message
        my $got = 0;
        if (!$p_state || 
            (   $p_exceptional eq $exceptional && 
                $p_whenlogged <= $whenlogged &&
                $p_state eq $state && 
                $p_editor eq $editor)
            ) {
                if (!$p_state || (!$matching_pairs && $p_message eq $message)) {
                    # Either at beginning, or message same as last one
                    push @dups, $order_id;
                    $got = 1;
                } elsif (!$matching_pairs && scalar(@dups) == 1) {
                    # Start looking for pair matches
                    $matching_pairs = 1;
                    push @dups, $order_id;
                    $got = 1;
                } elsif ($matching_pairs && $p_p_message eq $message) {
                    # Message same as one two ago
                    push @dups, $order_id;
                    $got = 1;
                } elsif (!$matching_threes && scalar(@dups) == 2) {
                    # Start looking for three matches
                    $matching_threes = 1;
                    push @dups, $order_id;
                    $got = 1;
                } elsif ($matching_threes && $p_p_p_message eq $message) {
                    # Message same as one three ago
                    push @dups, $order_id;
                    $got = 1;
                }
        } 
        if (!$got) {
            # If we got more than one row, then merge in 
            if ($matching_threes && scalar(@dups) >= 8) {
                merge_messages(\@dups, $c_extra, 3);
            } elsif ($matching_pairs && scalar(@dups) >= 8) { # higher tolerance for pairs
                merge_messages(\@dups, $c_extra, 2);
            } elsif (!$matching_pairs && scalar(@dups) >= 2) {
                merge_messages(\@dups, $c_extra, 1);
            }
            # Reset
            @dups = ($order_id);
            $c_extra = 0;
            $matching_pairs = 0;
            $matching_threes = 0;
        }
        $p_p_p_message = $p_p_message;
        $p_p_message = $p_message;
        $p_exceptional = $exceptional;
        $p_whenlogged = $whenlogged;
        $p_state = $state;
        $p_message = $message;
        $p_editor = $editor;
    }
    if ($matching_threes && scalar(@dups) >= 8) {
        merge_messages(\@dups, $c_extra, 3);
    } elsif ($matching_pairs && scalar(@dups) >= 8) { # higher tolerance for pairs
        merge_messages(\@dups, $c_extra, 2);
    } elsif (!$matching_pairs && scalar(@dups) >= 2) {
        merge_messages(\@dups, $c_extra, 1);
    }
}

#reduce_log('7f715e54e05dd8428f8a');
#exit;

my $one_id = "";
if (defined($ARGV[0])) {
    $one_id = " and message_id = '" . $ARGV[0] . "'";
}

# Read everything with lots of duplicates, using heuristic here
my $st = dbh()->prepare("select count(*) as c, message_id, message
    from message_log group by message_id, message having count(*) > $low $one_id order by c desc");
$st->execute();
while (my ($count, $message_id, $message) = $st->fetchrow_array()) {
    my ($total_rows) = dbh()->selectrow_array("select count(*) from message_log");
    print "Total rows: $total_rows\n"; 

    # Do proper merging of adjacent items
    print "Reducing $message_id $message...\n";
    reduce_log($message_id);
}

